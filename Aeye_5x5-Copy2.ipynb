{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5#학습 횟수\n",
    "batch_size=676\n",
    "test_batch_size = 676\n",
    "learning_rate = 0.005\n",
    "momentum = 0.5\n",
    "no_cuda = True\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position shape: (75712,)\n",
      "position 4 Sensor: [0 0 0 0]\n",
      "Sensor shape: (75712, 5)\n",
      "First 4 Sensor: [[ 655  650  652 1546 1524]\n",
      " [ 658  653  528 1522 1513]\n",
      " [ 660  648  644 1507 1492]\n",
      " [ 659  650  633 1490 1474]]\n"
     ]
    }
   ],
   "source": [
    "print_data = pd.read_csv(r'C:\\Users\\dorit\\anaconda3\\data\\Aeye\\KHMtest2_5x5.csv')\n",
    "#csv파일을 불러오기. 각자의 폴더 위치에 맞게 조정\n",
    "\n",
    "#데이터 확인\n",
    "data_position = print_data.iloc[:, 0]\n",
    "data_position = np.asarray(data_position)\n",
    "Sensor = print_data.iloc[:, 1:]\n",
    "Sensor = np.asarray(Sensor)\n",
    "print('position shape: {}'.format(data_position.shape))\n",
    "print('position 4 Sensor: {}'.format(data_position[:4]))\n",
    "print('Sensor shape: {}'.format(Sensor.shape))\n",
    "print('First 4 Sensor: {}'.format(Sensor[:4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataest 설정\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self): \n",
    "        self.len = data_position.shape[0]\n",
    "        self.x_data = torch.from_numpy(Sensor)\n",
    "        self.y_data = torch.from_numpy(data_position)\n",
    "\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index): \n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self): \n",
    "        return self.len \n",
    "    \n",
    "dataset1 = Dataset() \n",
    "train_loader = DataLoader(dataset=dataset1, batch_size=676, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = DataLoader(dataset=dataset1, batch_size=676, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([676, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 설정\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 200)\n",
    "        self.fc2 = nn.Linear(200, 300)\n",
    "        self.fc3 = nn.Linear(300, 500)\n",
    "        self.fc4 = nn.Linear(500, 400)\n",
    "        self.fc5 = nn.Linear(400, 300)\n",
    "        self.fc6 = nn.Linear(300, 5*5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bn1 = nn.BatchNorm1d(200)\n",
    "        self.bn2 = nn.BatchNorm1d(300)\n",
    "        self.bn3 = nn.BatchNorm1d(500)\n",
    "        self.bn4 = nn.BatchNorm1d(400)\n",
    "        self.bn5 = nn.BatchNorm1d(300)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.bn1(self.fc1(x)))\n",
    "        x = self.sigmoid(self.bn2(self.fc2(x)))\n",
    "        x = self.sigmoid(self.bn3(self.fc3(x)))\n",
    "        x = self.sigmoid(self.bn4(self.fc4(x)))\n",
    "        x = self.sigmoid(self.bn5(self.fc5(x)))\n",
    "        y_pred = self.sigmoid(self.fc6(x))\n",
    "        return y_pred\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([200, 5])\n",
      "fc1.bias \t torch.Size([200])\n",
      "fc2.weight \t torch.Size([300, 200])\n",
      "fc2.bias \t torch.Size([300])\n",
      "fc3.weight \t torch.Size([500, 300])\n",
      "fc3.bias \t torch.Size([500])\n",
      "fc4.weight \t torch.Size([400, 500])\n",
      "fc4.bias \t torch.Size([400])\n",
      "fc5.weight \t torch.Size([300, 400])\n",
      "fc5.bias \t torch.Size([300])\n",
      "fc6.weight \t torch.Size([25, 300])\n",
      "fc6.bias \t torch.Size([25])\n",
      "bn1.weight \t torch.Size([200])\n",
      "bn1.bias \t torch.Size([200])\n",
      "bn1.running_mean \t torch.Size([200])\n",
      "bn1.running_var \t torch.Size([200])\n",
      "bn1.num_batches_tracked \t torch.Size([])\n",
      "bn2.weight \t torch.Size([300])\n",
      "bn2.bias \t torch.Size([300])\n",
      "bn2.running_mean \t torch.Size([300])\n",
      "bn2.running_var \t torch.Size([300])\n",
      "bn2.num_batches_tracked \t torch.Size([])\n",
      "bn3.weight \t torch.Size([500])\n",
      "bn3.bias \t torch.Size([500])\n",
      "bn3.running_mean \t torch.Size([500])\n",
      "bn3.running_var \t torch.Size([500])\n",
      "bn3.num_batches_tracked \t torch.Size([])\n",
      "bn4.weight \t torch.Size([400])\n",
      "bn4.bias \t torch.Size([400])\n",
      "bn4.running_mean \t torch.Size([400])\n",
      "bn4.running_var \t torch.Size([400])\n",
      "bn4.num_batches_tracked \t torch.Size([])\n",
      "bn5.weight \t torch.Size([300])\n",
      "bn5.bias \t torch.Size([300])\n",
      "bn5.running_mean \t torch.Size([300])\n",
      "bn5.running_var \t torch.Size([300])\n",
      "bn5.num_batches_tracked \t torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dorit\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "#Optimizer 설정\n",
    "criterion = nn.MSELoss(size_average = True, reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data_check = pd.read_csv(r'C:\\Users\\dorit\\anaconda3\\data\\Aeye\\KHMtest2_5x5_Check.csv')\n",
    "#Check 을 위한 csv파일을 불러오기. 각자의 폴더 위치에 맞게 조정\n",
    "\n",
    "#데이터 확인\n",
    "data_position_check = print_data_check.iloc[:, 0]\n",
    "data_position_check = np.asarray(data_position_check)\n",
    "Sensor_check = print_data_check.iloc[:, 1:]\n",
    "Sensor_check = np.asarray(Sensor_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking을 위한 테스트 dataset 구축\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self): \n",
    "        self.len = data_position_check.shape[0]\n",
    "        self.x_data = torch.from_numpy(Sensor_check)\n",
    "        self.y_data = torch.from_numpy(data_position_check)\n",
    "\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index): \n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self): \n",
    "        return self.len \n",
    "    \n",
    "dataset3 = Dataset() \n",
    "train_loader_check = DataLoader(dataset=dataset3, batch_size=676, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 5])\n",
      "torch.Size([11, 25])\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(5)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(10)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(7)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(8)\n",
      "Pred is  ( tensor(1)  ,  tensor(1) Real Label is tensor(6)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(19)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(17)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(18)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(24)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(20)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(21)\n"
     ]
    }
   ],
   "source": [
    "#check 한 Pred 값과 실제 Label값 비교\n",
    "\n",
    "for i, data in enumerate(train_loader_check): \n",
    "    # get the inputs \n",
    "    inputs, labels = data \n",
    "    # wrap them in Variable \n",
    "    inputs, labels = Variable(inputs), Variable(labels) \n",
    "    # Forward pass: Compute predicted y by passing x to the model \n",
    "    print(inputs.size())\n",
    "    y_pred = model(inputs.float())\n",
    "    print(y_pred.size())\n",
    "    for j in range(11):\n",
    "        print(\"Pred is \", \"(\",(torch.argmax(y_pred[j])+1)//5,\" , \",(torch.argmax(y_pred[j])+1)%5, \"Real Label is\", labels[j])\n",
    "\n",
    "    # Compute and print loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 tensor(0.2709)\n",
      "1 1 tensor(0.2700)\n",
      "1 2 tensor(0.2683)\n",
      "1 3 tensor(0.2674)\n",
      "1 4 tensor(0.2656)\n",
      "1 5 tensor(0.2639)\n",
      "1 6 tensor(0.2624)\n",
      "1 7 tensor(0.2609)\n",
      "1 8 tensor(0.2591)\n",
      "1 9 tensor(0.2574)\n",
      "1 10 tensor(0.2559)\n",
      "1 11 tensor(0.2540)\n",
      "1 12 tensor(0.2526)\n",
      "1 13 tensor(0.2510)\n",
      "1 14 tensor(0.2494)\n",
      "1 15 tensor(0.2478)\n",
      "1 16 tensor(0.2462)\n",
      "1 17 tensor(0.2447)\n",
      "1 18 tensor(0.2432)\n",
      "1 19 tensor(0.2417)\n",
      "1 20 tensor(0.2401)\n",
      "1 21 tensor(0.2385)\n",
      "1 22 tensor(0.2371)\n",
      "1 23 tensor(0.2356)\n",
      "1 24 tensor(0.2340)\n",
      "1 25 tensor(0.2327)\n",
      "1 26 tensor(0.2312)\n",
      "1 27 tensor(0.2297)\n",
      "1 28 tensor(0.2283)\n",
      "1 29 tensor(0.2270)\n",
      "1 30 tensor(0.2256)\n",
      "1 31 tensor(0.2241)\n",
      "1 32 tensor(0.2227)\n",
      "1 33 tensor(0.2214)\n",
      "1 34 tensor(0.2199)\n",
      "1 35 tensor(0.2186)\n",
      "1 36 tensor(0.2173)\n",
      "1 37 tensor(0.2159)\n",
      "1 38 tensor(0.2145)\n",
      "1 39 tensor(0.2132)\n",
      "1 40 tensor(0.2119)\n",
      "1 41 tensor(0.2105)\n",
      "1 42 tensor(0.2094)\n",
      "1 43 tensor(0.2082)\n",
      "1 44 tensor(0.2068)\n",
      "1 45 tensor(0.2056)\n",
      "1 46 tensor(0.2043)\n",
      "1 47 tensor(0.2031)\n",
      "1 48 tensor(0.2019)\n",
      "1 49 tensor(0.2006)\n",
      "1 50 tensor(0.1994)\n",
      "1 51 tensor(0.1982)\n",
      "1 52 tensor(0.1971)\n",
      "1 53 tensor(0.1959)\n",
      "1 54 tensor(0.1947)\n",
      "1 55 tensor(0.1935)\n",
      "1 56 tensor(0.1924)\n",
      "1 57 tensor(0.1913)\n",
      "1 58 tensor(0.1901)\n",
      "1 59 tensor(0.1891)\n",
      "1 60 tensor(0.1879)\n",
      "1 61 tensor(0.1868)\n",
      "1 62 tensor(0.1858)\n",
      "1 63 tensor(0.1847)\n",
      "1 64 tensor(0.1836)\n",
      "1 65 tensor(0.1826)\n",
      "1 66 tensor(0.1815)\n",
      "1 67 tensor(0.1803)\n",
      "1 68 tensor(0.1794)\n",
      "1 69 tensor(0.1783)\n",
      "1 70 tensor(0.1774)\n",
      "1 71 tensor(0.1762)\n",
      "1 72 tensor(0.1753)\n",
      "1 73 tensor(0.1743)\n",
      "1 74 tensor(0.1733)\n",
      "1 75 tensor(0.1723)\n",
      "1 76 tensor(0.1714)\n",
      "1 77 tensor(0.1705)\n",
      "1 78 tensor(0.1696)\n",
      "1 79 tensor(0.1685)\n",
      "1 80 tensor(0.1677)\n",
      "1 81 tensor(0.1668)\n",
      "1 82 tensor(0.1659)\n",
      "1 83 tensor(0.1649)\n",
      "1 84 tensor(0.1640)\n",
      "1 85 tensor(0.1632)\n",
      "1 86 tensor(0.1621)\n",
      "1 87 tensor(0.1613)\n",
      "1 88 tensor(0.1605)\n",
      "1 89 tensor(0.1595)\n",
      "1 90 tensor(0.1588)\n",
      "1 91 tensor(0.1579)\n",
      "1 92 tensor(0.1571)\n",
      "1 93 tensor(0.1563)\n",
      "1 94 tensor(0.1554)\n",
      "1 95 tensor(0.1547)\n",
      "1 96 tensor(0.1538)\n",
      "1 97 tensor(0.1531)\n",
      "1 98 tensor(0.1522)\n",
      "1 99 tensor(0.1513)\n",
      "1 100 tensor(0.1507)\n",
      "1 101 tensor(0.1499)\n",
      "1 102 tensor(0.1491)\n",
      "1 103 tensor(0.1484)\n",
      "1 104 tensor(0.1476)\n",
      "1 105 tensor(0.1468)\n",
      "1 106 tensor(0.1462)\n",
      "1 107 tensor(0.1454)\n",
      "1 108 tensor(0.1447)\n",
      "1 109 tensor(0.1440)\n",
      "1 110 tensor(0.1433)\n",
      "1 111 tensor(0.1425)\n",
      "2 0 tensor(0.1418)\n",
      "2 1 tensor(0.1412)\n",
      "2 2 tensor(0.1405)\n",
      "2 3 tensor(0.1398)\n",
      "2 4 tensor(0.1391)\n",
      "2 5 tensor(0.1384)\n",
      "2 6 tensor(0.1378)\n",
      "2 7 tensor(0.1371)\n",
      "2 8 tensor(0.1364)\n",
      "2 9 tensor(0.1358)\n",
      "2 10 tensor(0.1351)\n",
      "2 11 tensor(0.1345)\n",
      "2 12 tensor(0.1339)\n",
      "2 13 tensor(0.1334)\n",
      "2 14 tensor(0.1327)\n",
      "2 15 tensor(0.1320)\n",
      "2 16 tensor(0.1314)\n",
      "2 17 tensor(0.1309)\n",
      "2 18 tensor(0.1302)\n",
      "2 19 tensor(0.1296)\n",
      "2 20 tensor(0.1291)\n",
      "2 21 tensor(0.1285)\n",
      "2 22 tensor(0.1279)\n",
      "2 23 tensor(0.1273)\n",
      "2 24 tensor(0.1268)\n",
      "2 25 tensor(0.1262)\n",
      "2 26 tensor(0.1256)\n",
      "2 27 tensor(0.1251)\n",
      "2 28 tensor(0.1246)\n",
      "2 29 tensor(0.1240)\n",
      "2 30 tensor(0.1235)\n",
      "2 31 tensor(0.1230)\n",
      "2 32 tensor(0.1223)\n",
      "2 33 tensor(0.1219)\n",
      "2 34 tensor(0.1213)\n",
      "2 35 tensor(0.1209)\n",
      "2 36 tensor(0.1203)\n",
      "2 37 tensor(0.1198)\n",
      "2 38 tensor(0.1193)\n",
      "2 39 tensor(0.1188)\n",
      "2 40 tensor(0.1184)\n",
      "2 41 tensor(0.1178)\n",
      "2 42 tensor(0.1175)\n",
      "2 43 tensor(0.1169)\n",
      "2 44 tensor(0.1163)\n",
      "2 45 tensor(0.1160)\n",
      "2 46 tensor(0.1155)\n",
      "2 47 tensor(0.1150)\n",
      "2 48 tensor(0.1146)\n",
      "2 49 tensor(0.1141)\n",
      "2 50 tensor(0.1136)\n",
      "2 51 tensor(0.1132)\n",
      "2 52 tensor(0.1127)\n",
      "2 53 tensor(0.1123)\n",
      "2 54 tensor(0.1119)\n",
      "2 55 tensor(0.1114)\n",
      "2 56 tensor(0.1110)\n",
      "2 57 tensor(0.1106)\n",
      "2 58 tensor(0.1102)\n",
      "2 59 tensor(0.1097)\n",
      "2 60 tensor(0.1093)\n",
      "2 61 tensor(0.1089)\n",
      "2 62 tensor(0.1084)\n",
      "2 63 tensor(0.1081)\n",
      "2 64 tensor(0.1077)\n",
      "2 65 tensor(0.1073)\n",
      "2 66 tensor(0.1069)\n",
      "2 67 tensor(0.1065)\n",
      "2 68 tensor(0.1061)\n",
      "2 69 tensor(0.1057)\n",
      "2 70 tensor(0.1053)\n",
      "2 71 tensor(0.1050)\n",
      "2 72 tensor(0.1047)\n",
      "2 73 tensor(0.1043)\n",
      "2 74 tensor(0.1038)\n",
      "2 75 tensor(0.1035)\n",
      "2 76 tensor(0.1031)\n",
      "2 77 tensor(0.1028)\n",
      "2 78 tensor(0.1024)\n",
      "2 79 tensor(0.1020)\n",
      "2 80 tensor(0.1017)\n",
      "2 81 tensor(0.1013)\n",
      "2 82 tensor(0.1010)\n",
      "2 83 tensor(0.1005)\n",
      "2 84 tensor(0.1003)\n",
      "2 85 tensor(0.1000)\n",
      "2 86 tensor(0.0996)\n",
      "2 87 tensor(0.0993)\n",
      "2 88 tensor(0.0989)\n",
      "2 89 tensor(0.0985)\n",
      "2 90 tensor(0.0983)\n",
      "2 91 tensor(0.0979)\n",
      "2 92 tensor(0.0978)\n",
      "2 93 tensor(0.0974)\n",
      "2 94 tensor(0.0971)\n",
      "2 95 tensor(0.0967)\n",
      "2 96 tensor(0.0964)\n",
      "2 97 tensor(0.0960)\n",
      "2 98 tensor(0.0958)\n",
      "2 99 tensor(0.0955)\n",
      "2 100 tensor(0.0952)\n",
      "2 101 tensor(0.0949)\n",
      "2 102 tensor(0.0947)\n",
      "2 103 tensor(0.0943)\n",
      "2 104 tensor(0.0940)\n",
      "2 105 tensor(0.0937)\n",
      "2 106 tensor(0.0935)\n",
      "2 107 tensor(0.0931)\n",
      "2 108 tensor(0.0929)\n",
      "2 109 tensor(0.0926)\n",
      "2 110 tensor(0.0923)\n",
      "2 111 tensor(0.0920)\n",
      "3 0 tensor(0.0918)\n",
      "3 1 tensor(0.0914)\n",
      "3 2 tensor(0.0912)\n",
      "3 3 tensor(0.0910)\n",
      "3 4 tensor(0.0906)\n",
      "3 5 tensor(0.0904)\n",
      "3 6 tensor(0.0901)\n",
      "3 7 tensor(0.0899)\n",
      "3 8 tensor(0.0896)\n",
      "3 9 tensor(0.0893)\n",
      "3 10 tensor(0.0890)\n",
      "3 11 tensor(0.0889)\n",
      "3 12 tensor(0.0886)\n",
      "3 13 tensor(0.0883)\n",
      "3 14 tensor(0.0881)\n",
      "3 15 tensor(0.0878)\n",
      "3 16 tensor(0.0876)\n",
      "3 17 tensor(0.0874)\n",
      "3 18 tensor(0.0871)\n",
      "3 19 tensor(0.0869)\n",
      "3 20 tensor(0.0867)\n",
      "3 21 tensor(0.0864)\n",
      "3 22 tensor(0.0862)\n",
      "3 23 tensor(0.0860)\n",
      "3 24 tensor(0.0857)\n",
      "3 25 tensor(0.0855)\n",
      "3 26 tensor(0.0853)\n",
      "3 27 tensor(0.0850)\n",
      "3 28 tensor(0.0848)\n",
      "3 29 tensor(0.0845)\n",
      "3 30 tensor(0.0843)\n",
      "3 31 tensor(0.0841)\n",
      "3 32 tensor(0.0839)\n",
      "3 33 tensor(0.0838)\n",
      "3 34 tensor(0.0835)\n",
      "3 35 tensor(0.0832)\n",
      "3 36 tensor(0.0830)\n",
      "3 37 tensor(0.0828)\n",
      "3 38 tensor(0.0826)\n",
      "3 39 tensor(0.0824)\n",
      "3 40 tensor(0.0822)\n",
      "3 41 tensor(0.0820)\n",
      "3 42 tensor(0.0819)\n",
      "3 43 tensor(0.0816)\n",
      "3 44 tensor(0.0814)\n",
      "3 45 tensor(0.0812)\n",
      "3 46 tensor(0.0810)\n",
      "3 47 tensor(0.0809)\n",
      "3 48 tensor(0.0806)\n",
      "3 49 tensor(0.0805)\n",
      "3 50 tensor(0.0802)\n",
      "3 51 tensor(0.0801)\n",
      "3 52 tensor(0.0799)\n",
      "3 53 tensor(0.0797)\n",
      "3 54 tensor(0.0795)\n",
      "3 55 tensor(0.0793)\n",
      "3 56 tensor(0.0792)\n",
      "3 57 tensor(0.0790)\n",
      "3 58 tensor(0.0787)\n",
      "3 59 tensor(0.0786)\n",
      "3 60 tensor(0.0784)\n",
      "3 61 tensor(0.0782)\n",
      "3 62 tensor(0.0780)\n",
      "3 63 tensor(0.0778)\n",
      "3 64 tensor(0.0776)\n",
      "3 65 tensor(0.0775)\n",
      "3 66 tensor(0.0774)\n",
      "3 67 tensor(0.0771)\n",
      "3 68 tensor(0.0770)\n",
      "3 69 tensor(0.0768)\n",
      "3 70 tensor(0.0767)\n",
      "3 71 tensor(0.0765)\n",
      "3 72 tensor(0.0763)\n",
      "3 73 tensor(0.0763)\n",
      "3 74 tensor(0.0760)\n",
      "3 75 tensor(0.0758)\n",
      "3 76 tensor(0.0757)\n",
      "3 77 tensor(0.0755)\n",
      "3 78 tensor(0.0754)\n",
      "3 79 tensor(0.0752)\n",
      "3 80 tensor(0.0750)\n",
      "3 81 tensor(0.0748)\n",
      "3 82 tensor(0.0746)\n",
      "3 83 tensor(0.0746)\n",
      "3 84 tensor(0.0743)\n",
      "3 85 tensor(0.0742)\n",
      "3 86 tensor(0.0741)\n",
      "3 87 tensor(0.0740)\n",
      "3 88 tensor(0.0738)\n",
      "3 89 tensor(0.0737)\n",
      "3 90 tensor(0.0734)\n",
      "3 91 tensor(0.0734)\n",
      "3 92 tensor(0.0733)\n",
      "3 93 tensor(0.0731)\n",
      "3 94 tensor(0.0729)\n",
      "3 95 tensor(0.0727)\n",
      "3 96 tensor(0.0726)\n",
      "3 97 tensor(0.0725)\n",
      "3 98 tensor(0.0723)\n",
      "3 99 tensor(0.0722)\n",
      "3 100 tensor(0.0720)\n",
      "3 101 tensor(0.0719)\n",
      "3 102 tensor(0.0717)\n",
      "3 103 tensor(0.0716)\n",
      "3 104 tensor(0.0714)\n",
      "3 105 tensor(0.0714)\n",
      "3 106 tensor(0.0712)\n",
      "3 107 tensor(0.0711)\n",
      "3 108 tensor(0.0709)\n",
      "3 109 tensor(0.0708)\n",
      "3 110 tensor(0.0707)\n",
      "3 111 tensor(0.0706)\n",
      "4 0 tensor(0.0704)\n",
      "4 1 tensor(0.0703)\n",
      "4 2 tensor(0.0702)\n",
      "4 3 tensor(0.0701)\n",
      "4 4 tensor(0.0698)\n",
      "4 5 tensor(0.0698)\n",
      "4 6 tensor(0.0697)\n",
      "4 7 tensor(0.0695)\n",
      "4 8 tensor(0.0694)\n",
      "4 9 tensor(0.0693)\n",
      "4 10 tensor(0.0691)\n",
      "4 11 tensor(0.0690)\n",
      "4 12 tensor(0.0689)\n",
      "4 13 tensor(0.0688)\n",
      "4 14 tensor(0.0687)\n",
      "4 15 tensor(0.0685)\n",
      "4 16 tensor(0.0684)\n",
      "4 17 tensor(0.0683)\n",
      "4 18 tensor(0.0682)\n",
      "4 19 tensor(0.0682)\n",
      "4 20 tensor(0.0680)\n",
      "4 21 tensor(0.0678)\n",
      "4 22 tensor(0.0678)\n",
      "4 23 tensor(0.0677)\n",
      "4 24 tensor(0.0675)\n",
      "4 25 tensor(0.0674)\n",
      "4 26 tensor(0.0673)\n",
      "4 27 tensor(0.0673)\n",
      "4 28 tensor(0.0671)\n",
      "4 29 tensor(0.0670)\n",
      "4 30 tensor(0.0669)\n",
      "4 31 tensor(0.0667)\n",
      "4 32 tensor(0.0667)\n",
      "4 33 tensor(0.0666)\n",
      "4 34 tensor(0.0664)\n",
      "4 35 tensor(0.0664)\n",
      "4 36 tensor(0.0662)\n",
      "4 37 tensor(0.0662)\n",
      "4 38 tensor(0.0660)\n",
      "4 39 tensor(0.0660)\n",
      "4 40 tensor(0.0658)\n",
      "4 41 tensor(0.0657)\n",
      "4 42 tensor(0.0656)\n",
      "4 43 tensor(0.0656)\n",
      "4 44 tensor(0.0654)\n",
      "4 45 tensor(0.0654)\n",
      "4 46 tensor(0.0652)\n",
      "4 47 tensor(0.0651)\n",
      "4 48 tensor(0.0650)\n",
      "4 49 tensor(0.0650)\n",
      "4 50 tensor(0.0648)\n",
      "4 51 tensor(0.0647)\n",
      "4 52 tensor(0.0646)\n",
      "4 53 tensor(0.0644)\n",
      "4 54 tensor(0.0644)\n",
      "4 55 tensor(0.0643)\n",
      "4 56 tensor(0.0643)\n",
      "4 57 tensor(0.0641)\n",
      "4 58 tensor(0.0641)\n",
      "4 59 tensor(0.0640)\n",
      "4 60 tensor(0.0640)\n",
      "4 61 tensor(0.0638)\n",
      "4 62 tensor(0.0637)\n",
      "4 63 tensor(0.0635)\n",
      "4 64 tensor(0.0635)\n",
      "4 65 tensor(0.0634)\n",
      "4 66 tensor(0.0632)\n",
      "4 67 tensor(0.0633)\n",
      "4 68 tensor(0.0631)\n",
      "4 69 tensor(0.0630)\n",
      "4 70 tensor(0.0630)\n",
      "4 71 tensor(0.0629)\n",
      "4 72 tensor(0.0627)\n",
      "4 73 tensor(0.0627)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 74 tensor(0.0627)\n",
      "4 75 tensor(0.0626)\n",
      "4 76 tensor(0.0625)\n",
      "4 77 tensor(0.0624)\n",
      "4 78 tensor(0.0622)\n",
      "4 79 tensor(0.0622)\n",
      "4 80 tensor(0.0621)\n",
      "4 81 tensor(0.0620)\n",
      "4 82 tensor(0.0619)\n",
      "4 83 tensor(0.0617)\n",
      "4 84 tensor(0.0619)\n",
      "4 85 tensor(0.0616)\n",
      "4 86 tensor(0.0615)\n",
      "4 87 tensor(0.0616)\n",
      "4 88 tensor(0.0615)\n",
      "4 89 tensor(0.0614)\n",
      "4 90 tensor(0.0613)\n",
      "4 91 tensor(0.0612)\n",
      "4 92 tensor(0.0612)\n",
      "4 93 tensor(0.0610)\n",
      "4 94 tensor(0.0610)\n",
      "4 95 tensor(0.0609)\n",
      "4 96 tensor(0.0609)\n",
      "4 97 tensor(0.0607)\n",
      "4 98 tensor(0.0607)\n",
      "4 99 tensor(0.0607)\n",
      "4 100 tensor(0.0605)\n",
      "4 101 tensor(0.0604)\n",
      "4 102 tensor(0.0604)\n",
      "4 103 tensor(0.0603)\n",
      "4 104 tensor(0.0602)\n",
      "4 105 tensor(0.0602)\n",
      "4 106 tensor(0.0601)\n",
      "4 107 tensor(0.0600)\n",
      "4 108 tensor(0.0600)\n",
      "4 109 tensor(0.0599)\n",
      "4 110 tensor(0.0598)\n",
      "4 111 tensor(0.0597)\n",
      "5 0 tensor(0.0596)\n",
      "5 1 tensor(0.0596)\n",
      "5 2 tensor(0.0595)\n",
      "5 3 tensor(0.0594)\n",
      "5 4 tensor(0.0593)\n",
      "5 5 tensor(0.0593)\n",
      "5 6 tensor(0.0593)\n",
      "5 7 tensor(0.0591)\n",
      "5 8 tensor(0.0590)\n",
      "5 9 tensor(0.0590)\n",
      "5 10 tensor(0.0589)\n",
      "5 11 tensor(0.0589)\n",
      "5 12 tensor(0.0588)\n",
      "5 13 tensor(0.0587)\n",
      "5 14 tensor(0.0587)\n",
      "5 15 tensor(0.0585)\n",
      "5 16 tensor(0.0585)\n",
      "5 17 tensor(0.0585)\n",
      "5 18 tensor(0.0584)\n",
      "5 19 tensor(0.0584)\n",
      "5 20 tensor(0.0583)\n",
      "5 21 tensor(0.0582)\n",
      "5 22 tensor(0.0581)\n",
      "5 23 tensor(0.0580)\n",
      "5 24 tensor(0.0581)\n",
      "5 25 tensor(0.0579)\n",
      "5 26 tensor(0.0579)\n",
      "5 27 tensor(0.0579)\n",
      "5 28 tensor(0.0577)\n",
      "5 29 tensor(0.0576)\n",
      "5 30 tensor(0.0576)\n",
      "5 31 tensor(0.0577)\n",
      "5 32 tensor(0.0575)\n",
      "5 33 tensor(0.0574)\n",
      "5 34 tensor(0.0573)\n",
      "5 35 tensor(0.0574)\n",
      "5 36 tensor(0.0573)\n",
      "5 37 tensor(0.0572)\n",
      "5 38 tensor(0.0572)\n",
      "5 39 tensor(0.0572)\n",
      "5 40 tensor(0.0571)\n",
      "5 41 tensor(0.0570)\n",
      "5 42 tensor(0.0569)\n",
      "5 43 tensor(0.0569)\n",
      "5 44 tensor(0.0568)\n",
      "5 45 tensor(0.0568)\n",
      "5 46 tensor(0.0567)\n",
      "5 47 tensor(0.0567)\n",
      "5 48 tensor(0.0566)\n",
      "5 49 tensor(0.0565)\n",
      "5 50 tensor(0.0565)\n",
      "5 51 tensor(0.0564)\n",
      "5 52 tensor(0.0563)\n",
      "5 53 tensor(0.0563)\n",
      "5 54 tensor(0.0561)\n",
      "5 55 tensor(0.0561)\n",
      "5 56 tensor(0.0561)\n",
      "5 57 tensor(0.0561)\n",
      "5 58 tensor(0.0560)\n",
      "5 59 tensor(0.0559)\n",
      "5 60 tensor(0.0560)\n",
      "5 61 tensor(0.0558)\n",
      "5 62 tensor(0.0558)\n",
      "5 63 tensor(0.0558)\n",
      "5 64 tensor(0.0557)\n",
      "5 65 tensor(0.0557)\n",
      "5 66 tensor(0.0556)\n",
      "5 67 tensor(0.0555)\n",
      "5 68 tensor(0.0555)\n",
      "5 69 tensor(0.0554)\n",
      "5 70 tensor(0.0553)\n",
      "5 71 tensor(0.0554)\n",
      "5 72 tensor(0.0552)\n",
      "5 73 tensor(0.0553)\n",
      "5 74 tensor(0.0551)\n",
      "5 75 tensor(0.0551)\n",
      "5 76 tensor(0.0550)\n",
      "5 77 tensor(0.0550)\n",
      "5 78 tensor(0.0550)\n",
      "5 79 tensor(0.0550)\n",
      "5 80 tensor(0.0549)\n",
      "5 81 tensor(0.0548)\n",
      "5 82 tensor(0.0548)\n",
      "5 83 tensor(0.0548)\n",
      "5 84 tensor(0.0547)\n",
      "5 85 tensor(0.0546)\n",
      "5 86 tensor(0.0546)\n",
      "5 87 tensor(0.0545)\n",
      "5 88 tensor(0.0544)\n",
      "5 89 tensor(0.0544)\n",
      "5 90 tensor(0.0543)\n",
      "5 91 tensor(0.0543)\n",
      "5 92 tensor(0.0543)\n",
      "5 93 tensor(0.0543)\n",
      "5 94 tensor(0.0543)\n",
      "5 95 tensor(0.0542)\n",
      "5 96 tensor(0.0541)\n",
      "5 97 tensor(0.0541)\n",
      "5 98 tensor(0.0539)\n",
      "5 99 tensor(0.0540)\n",
      "5 100 tensor(0.0540)\n",
      "5 101 tensor(0.0539)\n",
      "5 102 tensor(0.0539)\n",
      "5 103 tensor(0.0537)\n",
      "5 104 tensor(0.0537)\n",
      "5 105 tensor(0.0537)\n",
      "5 106 tensor(0.0537)\n",
      "5 107 tensor(0.0536)\n",
      "5 108 tensor(0.0535)\n",
      "5 109 tensor(0.0535)\n",
      "5 110 tensor(0.0535)\n",
      "5 111 tensor(0.0535)\n"
     ]
    }
   ],
   "source": [
    "#train 1번째 방법, 2번째 방법 사용시 이부분 스킵혹은 주석처리\n",
    "new_labels = torch.zeros(676, 25)\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(epochs + 1)]\n",
    "for epoch in range(1,epochs+1): \n",
    "    for i, data in enumerate(train_loader): \n",
    "        # get the inputs \n",
    "        inputs, labels = data \n",
    "\n",
    "        # wrap them in Variable \n",
    "        inputs, labels = Variable(inputs), Variable(labels) \n",
    "        for j in range(676):\n",
    "            for k in range(25):\n",
    "                new_labels[labels[j], labels[k]] = 1\n",
    "        # Forward pass: Compute predicted y by passing x to the model \n",
    "        y_pred = model(inputs.float()) \n",
    "        # Compute and print loss \n",
    "        loss = criterion(y_pred, new_labels.float()) \n",
    "        print(epoch, i, loss.data)\n",
    "        \n",
    "        # Zero gradients, perform a backward pass, and update the weights. \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291726ecac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data_check = pd.read_csv(r'C:\\Users\\dorit\\anaconda3\\data\\Aeye\\KHMtest2_5x5_Check.csv')\n",
    "#Check 을 위한 csv파일을 불러오기. 각자의 폴더 위치에 맞게 조정\n",
    "\n",
    "#데이터 확인\n",
    "data_position_check = print_data_check.iloc[:, 0]\n",
    "data_position_check = np.asarray(data_position_check)\n",
    "Sensor_check = print_data_check.iloc[:, 1:]\n",
    "Sensor_check = np.asarray(Sensor_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking을 위한 테스트 dataset 구축\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self): \n",
    "        self.len = data_position_check.shape[0]\n",
    "        self.x_data = torch.from_numpy(Sensor_check)\n",
    "        self.y_data = torch.from_numpy(data_position_check)\n",
    "\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index): \n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self): \n",
    "        return self.len \n",
    "    \n",
    "dataset3 = Dataset() \n",
    "train_loader_check = DataLoader(dataset=dataset3, batch_size=676, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 5])\n",
      "torch.Size([11, 25])\n",
      "Pred is  ( tensor(4)  ,  tensor(0) Real Label is tensor(5)\n",
      "Pred is  ( tensor(4)  ,  tensor(3) Real Label is tensor(10)\n",
      "Pred is  ( tensor(2)  ,  tensor(4) Real Label is tensor(7)\n",
      "Pred is  ( tensor(3)  ,  tensor(3) Real Label is tensor(8)\n",
      "Pred is  ( tensor(0)  ,  tensor(1) Real Label is tensor(6)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(19)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(17)\n",
      "Pred is  ( tensor(3)  ,  tensor(4) Real Label is tensor(18)\n",
      "Pred is  ( tensor(3)  ,  tensor(3) Real Label is tensor(24)\n",
      "Pred is  ( tensor(4)  ,  tensor(4) Real Label is tensor(20)\n",
      "Pred is  ( tensor(4)  ,  tensor(0) Real Label is tensor(21)\n"
     ]
    }
   ],
   "source": [
    "#check 한 Pred 값과 실제 Label값 비교\n",
    "\n",
    "for i, data in enumerate(train_loader_check): \n",
    "    # get the inputs \n",
    "    inputs, labels = data \n",
    "    # wrap them in Variable \n",
    "    inputs, labels = Variable(inputs), Variable(labels) \n",
    "    # Forward pass: Compute predicted y by passing x to the model \n",
    "    print(inputs.size())\n",
    "    y_pred = model(inputs.float())\n",
    "    print(y_pred.size())\n",
    "    for j in range(11):\n",
    "        print(\"Pred is \", \"(\",(torch.argmax(y_pred[j])+1)//5,\" , \",(torch.argmax(y_pred[j])+1)%5, \"Real Label is\", labels[j])\n",
    "\n",
    "    # Compute and print loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position shape: (75712,)\n",
      "position 4 Sensor: [0 0 0 0]\n",
      "Sensor shape: (75712, 5)\n",
      "First 4 Sensor: [[ 660  641  653 1337 1245]\n",
      " [ 649  647  648 1328 1247]\n",
      " [ 667  650  652 1328 1307]\n",
      " [ 653  645  620 1325 1314]]\n"
     ]
    }
   ],
   "source": [
    "print_data_wol = pd.read_csv(r'C:\\Users\\dorit\\anaconda3\\data\\Aeye\\KHMtest_without_lenz2_5x5.csv')\n",
    "#csv파일을 불러오기. 각자의 폴더 위치에 맞게 조정\n",
    "\n",
    "#데이터 확인\n",
    "data_position_wol = print_data_wol.iloc[:, 0]\n",
    "data_position_wol = np.asarray(data_position_wol)\n",
    "Sensor_wol = print_data_wol.iloc[:, 1:]\n",
    "Sensor_wol = np.asarray(Sensor_wol)\n",
    "print('position shape: {}'.format(data_position_wol.shape))\n",
    "print('position 4 Sensor: {}'.format(data_position_wol[:4]))\n",
    "print('Sensor shape: {}'.format(Sensor_wol.shape))\n",
    "print('First 4 Sensor: {}'.format(Sensor_wol[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self): \n",
    "        self.len = data_position_wol.shape[0]\n",
    "        self.x_data = torch.from_numpy(Sensor_wol)\n",
    "        self.y_data = torch.from_numpy(data_position_wol)\n",
    "\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index): \n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self): \n",
    "        return self.len\n",
    "    \n",
    "dataset2 = Dataset() \n",
    "train_loader_wol = DataLoader(dataset=dataset2, batch_size=676, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader_wol = DataLoader(dataset=dataset2, batch_size=676, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 설정\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 200)\n",
    "        self.fc2 = nn.Linear(200, 300)\n",
    "        self.fc3 = nn.Linear(300, 500)\n",
    "        self.fc4 = nn.Linear(500, 400)\n",
    "        self.fc5 = nn.Linear(400, 300)\n",
    "        self.fc6 = nn.Linear(300, 5*5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bn1 = nn.BatchNorm1d(200)\n",
    "        self.bn2 = nn.BatchNorm1d(300)\n",
    "        self.bn3 = nn.BatchNorm1d(500)\n",
    "        self.bn4 = nn.BatchNorm1d(400)\n",
    "        self.bn5 = nn.BatchNorm1d(300)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.bn1(self.fc1(x)))\n",
    "        x = self.sigmoid(self.bn2(self.fc2(x)))\n",
    "        x = self.sigmoid(self.bn3(self.fc3(x)))\n",
    "        x = self.sigmoid(self.bn4(self.fc4(x)))\n",
    "        x = self.sigmoid(self.bn5(self.fc5(x)))\n",
    "        y_pred = self.sigmoid(self.fc6(x))\n",
    "        return y_pred\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([200, 5])\n",
      "fc1.bias \t torch.Size([200])\n",
      "fc2.weight \t torch.Size([300, 200])\n",
      "fc2.bias \t torch.Size([300])\n",
      "fc3.weight \t torch.Size([500, 300])\n",
      "fc3.bias \t torch.Size([500])\n",
      "fc4.weight \t torch.Size([400, 500])\n",
      "fc4.bias \t torch.Size([400])\n",
      "fc5.weight \t torch.Size([300, 400])\n",
      "fc5.bias \t torch.Size([300])\n",
      "fc6.weight \t torch.Size([25, 300])\n",
      "fc6.bias \t torch.Size([25])\n",
      "bn1.weight \t torch.Size([200])\n",
      "bn1.bias \t torch.Size([200])\n",
      "bn1.running_mean \t torch.Size([200])\n",
      "bn1.running_var \t torch.Size([200])\n",
      "bn1.num_batches_tracked \t torch.Size([])\n",
      "bn2.weight \t torch.Size([300])\n",
      "bn2.bias \t torch.Size([300])\n",
      "bn2.running_mean \t torch.Size([300])\n",
      "bn2.running_var \t torch.Size([300])\n",
      "bn2.num_batches_tracked \t torch.Size([])\n",
      "bn3.weight \t torch.Size([500])\n",
      "bn3.bias \t torch.Size([500])\n",
      "bn3.running_mean \t torch.Size([500])\n",
      "bn3.running_var \t torch.Size([500])\n",
      "bn3.num_batches_tracked \t torch.Size([])\n",
      "bn4.weight \t torch.Size([400])\n",
      "bn4.bias \t torch.Size([400])\n",
      "bn4.running_mean \t torch.Size([400])\n",
      "bn4.running_var \t torch.Size([400])\n",
      "bn4.num_batches_tracked \t torch.Size([])\n",
      "bn5.weight \t torch.Size([300])\n",
      "bn5.bias \t torch.Size([300])\n",
      "bn5.running_mean \t torch.Size([300])\n",
      "bn5.running_var \t torch.Size([300])\n",
      "bn5.num_batches_tracked \t torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dorit\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "#Optimizer 설정\n",
    "criterion = nn.MSELoss(size_average = True, reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 tensor(0.2602)\n",
      "1 1 tensor(0.2592)\n",
      "1 2 tensor(0.2578)\n",
      "1 3 tensor(0.2562)\n",
      "1 4 tensor(0.2544)\n",
      "1 5 tensor(0.2526)\n",
      "1 6 tensor(0.2508)\n",
      "1 7 tensor(0.2490)\n",
      "1 8 tensor(0.2471)\n",
      "1 9 tensor(0.2454)\n",
      "1 10 tensor(0.2436)\n",
      "1 11 tensor(0.2418)\n",
      "1 12 tensor(0.2400)\n",
      "1 13 tensor(0.2383)\n",
      "1 14 tensor(0.2365)\n",
      "1 15 tensor(0.2348)\n",
      "1 16 tensor(0.2330)\n",
      "1 17 tensor(0.2314)\n",
      "1 18 tensor(0.2296)\n",
      "1 19 tensor(0.2280)\n",
      "1 20 tensor(0.2263)\n",
      "1 21 tensor(0.2246)\n",
      "1 22 tensor(0.2230)\n",
      "1 23 tensor(0.2213)\n",
      "1 24 tensor(0.2197)\n",
      "1 25 tensor(0.2181)\n",
      "1 26 tensor(0.2165)\n",
      "1 27 tensor(0.2149)\n",
      "1 28 tensor(0.2133)\n",
      "1 29 tensor(0.2117)\n",
      "1 30 tensor(0.2102)\n",
      "1 31 tensor(0.2086)\n",
      "1 32 tensor(0.2071)\n",
      "1 33 tensor(0.2056)\n",
      "1 34 tensor(0.2041)\n",
      "1 35 tensor(0.2027)\n",
      "1 36 tensor(0.2011)\n",
      "1 37 tensor(0.1997)\n",
      "1 38 tensor(0.1982)\n",
      "1 39 tensor(0.1968)\n",
      "1 40 tensor(0.1953)\n",
      "1 41 tensor(0.1939)\n",
      "1 42 tensor(0.1925)\n",
      "1 43 tensor(0.1911)\n",
      "1 44 tensor(0.1897)\n",
      "1 45 tensor(0.1884)\n",
      "1 46 tensor(0.1870)\n",
      "1 47 tensor(0.1856)\n",
      "1 48 tensor(0.1843)\n",
      "1 49 tensor(0.1830)\n",
      "1 50 tensor(0.1816)\n",
      "1 51 tensor(0.1803)\n",
      "1 52 tensor(0.1791)\n",
      "1 53 tensor(0.1777)\n",
      "1 54 tensor(0.1765)\n",
      "1 55 tensor(0.1752)\n",
      "1 56 tensor(0.1740)\n",
      "1 57 tensor(0.1727)\n",
      "1 58 tensor(0.1715)\n",
      "1 59 tensor(0.1703)\n",
      "1 60 tensor(0.1691)\n",
      "1 61 tensor(0.1679)\n",
      "1 62 tensor(0.1666)\n",
      "1 63 tensor(0.1655)\n",
      "1 64 tensor(0.1643)\n",
      "1 65 tensor(0.1632)\n",
      "1 66 tensor(0.1620)\n",
      "1 67 tensor(0.1609)\n",
      "1 68 tensor(0.1598)\n",
      "1 69 tensor(0.1586)\n",
      "1 70 tensor(0.1575)\n",
      "1 71 tensor(0.1564)\n",
      "1 72 tensor(0.1554)\n",
      "1 73 tensor(0.1543)\n",
      "1 74 tensor(0.1533)\n",
      "1 75 tensor(0.1522)\n",
      "1 76 tensor(0.1511)\n",
      "1 77 tensor(0.1501)\n",
      "1 78 tensor(0.1490)\n",
      "1 79 tensor(0.1480)\n",
      "1 80 tensor(0.1470)\n",
      "1 81 tensor(0.1460)\n",
      "1 82 tensor(0.1450)\n",
      "1 83 tensor(0.1440)\n",
      "1 84 tensor(0.1431)\n",
      "1 85 tensor(0.1421)\n",
      "1 86 tensor(0.1411)\n",
      "1 87 tensor(0.1402)\n",
      "1 88 tensor(0.1393)\n",
      "1 89 tensor(0.1383)\n",
      "1 90 tensor(0.1374)\n",
      "1 91 tensor(0.1364)\n",
      "1 92 tensor(0.1356)\n",
      "1 93 tensor(0.1347)\n",
      "1 94 tensor(0.1338)\n",
      "1 95 tensor(0.1329)\n",
      "1 96 tensor(0.1320)\n",
      "1 97 tensor(0.1312)\n",
      "1 98 tensor(0.1303)\n",
      "1 99 tensor(0.1294)\n",
      "1 100 tensor(0.1286)\n",
      "1 101 tensor(0.1278)\n",
      "1 102 tensor(0.1270)\n",
      "1 103 tensor(0.1261)\n",
      "1 104 tensor(0.1253)\n",
      "1 105 tensor(0.1246)\n",
      "1 106 tensor(0.1237)\n",
      "1 107 tensor(0.1229)\n",
      "1 108 tensor(0.1222)\n",
      "1 109 tensor(0.1214)\n",
      "1 110 tensor(0.1206)\n",
      "1 111 tensor(0.1198)\n",
      "2 0 tensor(0.1191)\n",
      "2 1 tensor(0.1183)\n",
      "2 2 tensor(0.1176)\n",
      "2 3 tensor(0.1169)\n",
      "2 4 tensor(0.1161)\n",
      "2 5 tensor(0.1154)\n",
      "2 6 tensor(0.1147)\n",
      "2 7 tensor(0.1140)\n",
      "2 8 tensor(0.1133)\n",
      "2 9 tensor(0.1126)\n",
      "2 10 tensor(0.1119)\n",
      "2 11 tensor(0.1112)\n",
      "2 12 tensor(0.1105)\n",
      "2 13 tensor(0.1099)\n",
      "2 14 tensor(0.1092)\n",
      "2 15 tensor(0.1085)\n",
      "2 16 tensor(0.1079)\n",
      "2 17 tensor(0.1073)\n",
      "2 18 tensor(0.1066)\n",
      "2 19 tensor(0.1060)\n",
      "2 20 tensor(0.1053)\n",
      "2 21 tensor(0.1047)\n",
      "2 22 tensor(0.1041)\n",
      "2 23 tensor(0.1035)\n",
      "2 24 tensor(0.1029)\n",
      "2 25 tensor(0.1023)\n",
      "2 26 tensor(0.1017)\n",
      "2 27 tensor(0.1011)\n",
      "2 28 tensor(0.1005)\n",
      "2 29 tensor(0.0999)\n",
      "2 30 tensor(0.0993)\n",
      "2 31 tensor(0.0988)\n",
      "2 32 tensor(0.0982)\n",
      "2 33 tensor(0.0976)\n",
      "2 34 tensor(0.0971)\n",
      "2 35 tensor(0.0965)\n",
      "2 36 tensor(0.0960)\n",
      "2 37 tensor(0.0954)\n",
      "2 38 tensor(0.0949)\n",
      "2 39 tensor(0.0944)\n",
      "2 40 tensor(0.0938)\n",
      "2 41 tensor(0.0933)\n",
      "2 42 tensor(0.0928)\n",
      "2 43 tensor(0.0923)\n",
      "2 44 tensor(0.0918)\n",
      "2 45 tensor(0.0913)\n",
      "2 46 tensor(0.0907)\n",
      "2 47 tensor(0.0903)\n",
      "2 48 tensor(0.0897)\n",
      "2 49 tensor(0.0893)\n",
      "2 50 tensor(0.0888)\n",
      "2 51 tensor(0.0883)\n",
      "2 52 tensor(0.0878)\n",
      "2 53 tensor(0.0874)\n",
      "2 54 tensor(0.0868)\n",
      "2 55 tensor(0.0864)\n",
      "2 56 tensor(0.0859)\n",
      "2 57 tensor(0.0855)\n",
      "2 58 tensor(0.0851)\n",
      "2 59 tensor(0.0846)\n",
      "2 60 tensor(0.0842)\n",
      "2 61 tensor(0.0837)\n",
      "2 62 tensor(0.0833)\n",
      "2 63 tensor(0.0828)\n",
      "2 64 tensor(0.0824)\n",
      "2 65 tensor(0.0820)\n",
      "2 66 tensor(0.0816)\n",
      "2 67 tensor(0.0812)\n",
      "2 68 tensor(0.0807)\n",
      "2 69 tensor(0.0803)\n",
      "2 70 tensor(0.0799)\n",
      "2 71 tensor(0.0795)\n",
      "2 72 tensor(0.0791)\n",
      "2 73 tensor(0.0787)\n",
      "2 74 tensor(0.0783)\n",
      "2 75 tensor(0.0779)\n",
      "2 76 tensor(0.0775)\n",
      "2 77 tensor(0.0772)\n",
      "2 78 tensor(0.0767)\n",
      "2 79 tensor(0.0764)\n",
      "2 80 tensor(0.0760)\n",
      "2 81 tensor(0.0756)\n",
      "2 82 tensor(0.0752)\n",
      "2 83 tensor(0.0749)\n",
      "2 84 tensor(0.0745)\n",
      "2 85 tensor(0.0741)\n",
      "2 86 tensor(0.0738)\n",
      "2 87 tensor(0.0734)\n",
      "2 88 tensor(0.0731)\n",
      "2 89 tensor(0.0727)\n",
      "2 90 tensor(0.0724)\n",
      "2 91 tensor(0.0720)\n",
      "2 92 tensor(0.0717)\n",
      "2 93 tensor(0.0713)\n",
      "2 94 tensor(0.0710)\n",
      "2 95 tensor(0.0707)\n",
      "2 96 tensor(0.0703)\n",
      "2 97 tensor(0.0700)\n",
      "2 98 tensor(0.0697)\n",
      "2 99 tensor(0.0693)\n",
      "2 100 tensor(0.0690)\n",
      "2 101 tensor(0.0687)\n",
      "2 102 tensor(0.0684)\n",
      "2 103 tensor(0.0681)\n",
      "2 104 tensor(0.0677)\n",
      "2 105 tensor(0.0674)\n",
      "2 106 tensor(0.0671)\n",
      "2 107 tensor(0.0669)\n",
      "2 108 tensor(0.0665)\n",
      "2 109 tensor(0.0662)\n",
      "2 110 tensor(0.0659)\n",
      "2 111 tensor(0.0656)\n",
      "3 0 tensor(0.0653)\n",
      "3 1 tensor(0.0651)\n",
      "3 2 tensor(0.0648)\n",
      "3 3 tensor(0.0645)\n",
      "3 4 tensor(0.0642)\n",
      "3 5 tensor(0.0639)\n",
      "3 6 tensor(0.0636)\n",
      "3 7 tensor(0.0633)\n",
      "3 8 tensor(0.0630)\n",
      "3 9 tensor(0.0628)\n",
      "3 10 tensor(0.0625)\n",
      "3 11 tensor(0.0622)\n",
      "3 12 tensor(0.0620)\n",
      "3 13 tensor(0.0617)\n",
      "3 14 tensor(0.0614)\n",
      "3 15 tensor(0.0612)\n",
      "3 16 tensor(0.0609)\n",
      "3 17 tensor(0.0606)\n",
      "3 18 tensor(0.0604)\n",
      "3 19 tensor(0.0601)\n",
      "3 20 tensor(0.0598)\n",
      "3 21 tensor(0.0596)\n",
      "3 22 tensor(0.0594)\n",
      "3 23 tensor(0.0591)\n",
      "3 24 tensor(0.0588)\n",
      "3 25 tensor(0.0586)\n",
      "3 26 tensor(0.0584)\n",
      "3 27 tensor(0.0581)\n",
      "3 28 tensor(0.0579)\n",
      "3 29 tensor(0.0576)\n",
      "3 30 tensor(0.0574)\n",
      "3 31 tensor(0.0572)\n",
      "3 32 tensor(0.0569)\n",
      "3 33 tensor(0.0567)\n",
      "3 34 tensor(0.0565)\n",
      "3 35 tensor(0.0562)\n",
      "3 36 tensor(0.0561)\n",
      "3 37 tensor(0.0558)\n",
      "3 38 tensor(0.0555)\n",
      "3 39 tensor(0.0554)\n",
      "3 40 tensor(0.0551)\n",
      "3 41 tensor(0.0549)\n",
      "3 42 tensor(0.0547)\n",
      "3 43 tensor(0.0545)\n",
      "3 44 tensor(0.0543)\n",
      "3 45 tensor(0.0540)\n",
      "3 46 tensor(0.0538)\n",
      "3 47 tensor(0.0536)\n",
      "3 48 tensor(0.0534)\n",
      "3 49 tensor(0.0532)\n",
      "3 50 tensor(0.0530)\n",
      "3 51 tensor(0.0528)\n",
      "3 52 tensor(0.0526)\n",
      "3 53 tensor(0.0524)\n",
      "3 54 tensor(0.0521)\n",
      "3 55 tensor(0.0520)\n",
      "3 56 tensor(0.0518)\n",
      "3 57 tensor(0.0516)\n",
      "3 58 tensor(0.0514)\n",
      "3 59 tensor(0.0512)\n",
      "3 60 tensor(0.0510)\n",
      "3 61 tensor(0.0508)\n",
      "3 62 tensor(0.0506)\n",
      "3 63 tensor(0.0504)\n",
      "3 64 tensor(0.0502)\n",
      "3 65 tensor(0.0500)\n",
      "3 66 tensor(0.0499)\n",
      "3 67 tensor(0.0497)\n",
      "3 68 tensor(0.0495)\n",
      "3 69 tensor(0.0493)\n",
      "3 70 tensor(0.0491)\n",
      "3 71 tensor(0.0489)\n",
      "3 72 tensor(0.0488)\n",
      "3 73 tensor(0.0486)\n",
      "3 74 tensor(0.0484)\n",
      "3 75 tensor(0.0482)\n",
      "3 76 tensor(0.0481)\n",
      "3 77 tensor(0.0479)\n",
      "3 78 tensor(0.0477)\n",
      "3 79 tensor(0.0475)\n",
      "3 80 tensor(0.0474)\n",
      "3 81 tensor(0.0472)\n",
      "3 82 tensor(0.0470)\n",
      "3 83 tensor(0.0468)\n",
      "3 84 tensor(0.0467)\n",
      "3 85 tensor(0.0465)\n",
      "3 86 tensor(0.0464)\n",
      "3 87 tensor(0.0462)\n",
      "3 88 tensor(0.0460)\n",
      "3 89 tensor(0.0459)\n",
      "3 90 tensor(0.0457)\n",
      "3 91 tensor(0.0456)\n",
      "3 92 tensor(0.0454)\n",
      "3 93 tensor(0.0452)\n",
      "3 94 tensor(0.0451)\n",
      "3 95 tensor(0.0449)\n",
      "3 96 tensor(0.0448)\n",
      "3 97 tensor(0.0446)\n",
      "3 98 tensor(0.0445)\n",
      "3 99 tensor(0.0443)\n",
      "3 100 tensor(0.0442)\n",
      "3 101 tensor(0.0440)\n",
      "3 102 tensor(0.0438)\n",
      "3 103 tensor(0.0437)\n",
      "3 104 tensor(0.0436)\n",
      "3 105 tensor(0.0434)\n",
      "3 106 tensor(0.0433)\n",
      "3 107 tensor(0.0431)\n",
      "3 108 tensor(0.0430)\n",
      "3 109 tensor(0.0428)\n",
      "3 110 tensor(0.0426)\n",
      "3 111 tensor(0.0426)\n",
      "4 0 tensor(0.0424)\n",
      "4 1 tensor(0.0423)\n",
      "4 2 tensor(0.0421)\n",
      "4 3 tensor(0.0420)\n",
      "4 4 tensor(0.0419)\n",
      "4 5 tensor(0.0417)\n",
      "4 6 tensor(0.0416)\n",
      "4 7 tensor(0.0415)\n",
      "4 8 tensor(0.0413)\n",
      "4 9 tensor(0.0412)\n",
      "4 10 tensor(0.0411)\n",
      "4 11 tensor(0.0409)\n",
      "4 12 tensor(0.0408)\n",
      "4 13 tensor(0.0406)\n",
      "4 14 tensor(0.0405)\n",
      "4 15 tensor(0.0404)\n",
      "4 16 tensor(0.0402)\n",
      "4 17 tensor(0.0401)\n",
      "4 18 tensor(0.0400)\n",
      "4 19 tensor(0.0399)\n",
      "4 20 tensor(0.0397)\n",
      "4 21 tensor(0.0396)\n",
      "4 22 tensor(0.0395)\n",
      "4 23 tensor(0.0394)\n",
      "4 24 tensor(0.0392)\n",
      "4 25 tensor(0.0391)\n",
      "4 26 tensor(0.0390)\n",
      "4 27 tensor(0.0389)\n",
      "4 28 tensor(0.0387)\n",
      "4 29 tensor(0.0386)\n",
      "4 30 tensor(0.0385)\n",
      "4 31 tensor(0.0384)\n",
      "4 32 tensor(0.0383)\n",
      "4 33 tensor(0.0382)\n",
      "4 34 tensor(0.0381)\n",
      "4 35 tensor(0.0379)\n",
      "4 36 tensor(0.0378)\n",
      "4 37 tensor(0.0377)\n",
      "4 38 tensor(0.0376)\n",
      "4 39 tensor(0.0375)\n",
      "4 40 tensor(0.0374)\n",
      "4 41 tensor(0.0373)\n",
      "4 42 tensor(0.0372)\n",
      "4 43 tensor(0.0370)\n",
      "4 44 tensor(0.0369)\n",
      "4 45 tensor(0.0368)\n",
      "4 46 tensor(0.0367)\n",
      "4 47 tensor(0.0366)\n",
      "4 48 tensor(0.0365)\n",
      "4 49 tensor(0.0364)\n",
      "4 50 tensor(0.0362)\n",
      "4 51 tensor(0.0362)\n",
      "4 52 tensor(0.0361)\n",
      "4 53 tensor(0.0359)\n",
      "4 54 tensor(0.0358)\n",
      "4 55 tensor(0.0357)\n",
      "4 56 tensor(0.0356)\n",
      "4 57 tensor(0.0355)\n",
      "4 58 tensor(0.0354)\n",
      "4 59 tensor(0.0354)\n",
      "4 60 tensor(0.0352)\n",
      "4 61 tensor(0.0351)\n",
      "4 62 tensor(0.0351)\n",
      "4 63 tensor(0.0349)\n",
      "4 64 tensor(0.0348)\n",
      "4 65 tensor(0.0347)\n",
      "4 66 tensor(0.0346)\n",
      "4 67 tensor(0.0345)\n",
      "4 68 tensor(0.0344)\n",
      "4 69 tensor(0.0344)\n",
      "4 70 tensor(0.0343)\n",
      "4 71 tensor(0.0342)\n",
      "4 72 tensor(0.0340)\n",
      "4 73 tensor(0.0340)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 74 tensor(0.0339)\n",
      "4 75 tensor(0.0338)\n",
      "4 76 tensor(0.0337)\n",
      "4 77 tensor(0.0336)\n",
      "4 78 tensor(0.0335)\n",
      "4 79 tensor(0.0334)\n",
      "4 80 tensor(0.0333)\n",
      "4 81 tensor(0.0332)\n",
      "4 82 tensor(0.0331)\n",
      "4 83 tensor(0.0330)\n",
      "4 84 tensor(0.0330)\n",
      "4 85 tensor(0.0329)\n",
      "4 86 tensor(0.0328)\n",
      "4 87 tensor(0.0327)\n",
      "4 88 tensor(0.0326)\n",
      "4 89 tensor(0.0325)\n",
      "4 90 tensor(0.0324)\n",
      "4 91 tensor(0.0323)\n",
      "4 92 tensor(0.0322)\n",
      "4 93 tensor(0.0322)\n",
      "4 94 tensor(0.0321)\n",
      "4 95 tensor(0.0320)\n",
      "4 96 tensor(0.0319)\n",
      "4 97 tensor(0.0318)\n",
      "4 98 tensor(0.0317)\n",
      "4 99 tensor(0.0316)\n",
      "4 100 tensor(0.0315)\n",
      "4 101 tensor(0.0315)\n",
      "4 102 tensor(0.0314)\n",
      "4 103 tensor(0.0313)\n",
      "4 104 tensor(0.0312)\n",
      "4 105 tensor(0.0312)\n",
      "4 106 tensor(0.0311)\n",
      "4 107 tensor(0.0310)\n",
      "4 108 tensor(0.0309)\n",
      "4 109 tensor(0.0308)\n",
      "4 110 tensor(0.0307)\n",
      "4 111 tensor(0.0307)\n",
      "5 0 tensor(0.0306)\n",
      "5 1 tensor(0.0305)\n",
      "5 2 tensor(0.0304)\n",
      "5 3 tensor(0.0303)\n",
      "5 4 tensor(0.0303)\n",
      "5 5 tensor(0.0302)\n",
      "5 6 tensor(0.0301)\n",
      "5 7 tensor(0.0300)\n",
      "5 8 tensor(0.0300)\n",
      "5 9 tensor(0.0299)\n",
      "5 10 tensor(0.0298)\n",
      "5 11 tensor(0.0297)\n",
      "5 12 tensor(0.0296)\n",
      "5 13 tensor(0.0296)\n",
      "5 14 tensor(0.0295)\n",
      "5 15 tensor(0.0295)\n",
      "5 16 tensor(0.0294)\n",
      "5 17 tensor(0.0293)\n",
      "5 18 tensor(0.0292)\n",
      "5 19 tensor(0.0292)\n",
      "5 20 tensor(0.0291)\n",
      "5 21 tensor(0.0290)\n",
      "5 22 tensor(0.0289)\n",
      "5 23 tensor(0.0289)\n",
      "5 24 tensor(0.0288)\n",
      "5 25 tensor(0.0287)\n",
      "5 26 tensor(0.0286)\n",
      "5 27 tensor(0.0286)\n",
      "5 28 tensor(0.0285)\n",
      "5 29 tensor(0.0284)\n",
      "5 30 tensor(0.0284)\n",
      "5 31 tensor(0.0283)\n",
      "5 32 tensor(0.0282)\n",
      "5 33 tensor(0.0282)\n",
      "5 34 tensor(0.0281)\n",
      "5 35 tensor(0.0280)\n",
      "5 36 tensor(0.0280)\n",
      "5 37 tensor(0.0279)\n",
      "5 38 tensor(0.0278)\n",
      "5 39 tensor(0.0278)\n",
      "5 40 tensor(0.0277)\n",
      "5 41 tensor(0.0276)\n",
      "5 42 tensor(0.0276)\n",
      "5 43 tensor(0.0275)\n",
      "5 44 tensor(0.0275)\n",
      "5 45 tensor(0.0273)\n",
      "5 46 tensor(0.0273)\n",
      "5 47 tensor(0.0273)\n",
      "5 48 tensor(0.0272)\n",
      "5 49 tensor(0.0271)\n",
      "5 50 tensor(0.0270)\n",
      "5 51 tensor(0.0270)\n",
      "5 52 tensor(0.0269)\n",
      "5 53 tensor(0.0269)\n",
      "5 54 tensor(0.0268)\n",
      "5 55 tensor(0.0268)\n",
      "5 56 tensor(0.0267)\n",
      "5 57 tensor(0.0266)\n",
      "5 58 tensor(0.0266)\n",
      "5 59 tensor(0.0265)\n",
      "5 60 tensor(0.0264)\n",
      "5 61 tensor(0.0264)\n",
      "5 62 tensor(0.0263)\n",
      "5 63 tensor(0.0262)\n",
      "5 64 tensor(0.0262)\n",
      "5 65 tensor(0.0261)\n",
      "5 66 tensor(0.0261)\n",
      "5 67 tensor(0.0260)\n",
      "5 68 tensor(0.0260)\n",
      "5 69 tensor(0.0259)\n",
      "5 70 tensor(0.0258)\n",
      "5 71 tensor(0.0258)\n",
      "5 72 tensor(0.0257)\n",
      "5 73 tensor(0.0257)\n",
      "5 74 tensor(0.0256)\n",
      "5 75 tensor(0.0256)\n",
      "5 76 tensor(0.0255)\n",
      "5 77 tensor(0.0254)\n",
      "5 78 tensor(0.0254)\n",
      "5 79 tensor(0.0253)\n",
      "5 80 tensor(0.0253)\n",
      "5 81 tensor(0.0252)\n",
      "5 82 tensor(0.0252)\n",
      "5 83 tensor(0.0251)\n",
      "5 84 tensor(0.0250)\n",
      "5 85 tensor(0.0250)\n",
      "5 86 tensor(0.0249)\n",
      "5 87 tensor(0.0249)\n",
      "5 88 tensor(0.0248)\n",
      "5 89 tensor(0.0248)\n",
      "5 90 tensor(0.0247)\n",
      "5 91 tensor(0.0247)\n",
      "5 92 tensor(0.0246)\n",
      "5 93 tensor(0.0246)\n",
      "5 94 tensor(0.0245)\n",
      "5 95 tensor(0.0245)\n",
      "5 96 tensor(0.0244)\n",
      "5 97 tensor(0.0244)\n",
      "5 98 tensor(0.0243)\n",
      "5 99 tensor(0.0242)\n",
      "5 100 tensor(0.0242)\n",
      "5 101 tensor(0.0242)\n",
      "5 102 tensor(0.0241)\n",
      "5 103 tensor(0.0241)\n",
      "5 104 tensor(0.0240)\n",
      "5 105 tensor(0.0240)\n",
      "5 106 tensor(0.0239)\n",
      "5 107 tensor(0.0239)\n",
      "5 108 tensor(0.0238)\n",
      "5 109 tensor(0.0237)\n",
      "5 110 tensor(0.0237)\n",
      "5 111 tensor(0.0236)\n"
     ]
    }
   ],
   "source": [
    "new_labels_wol = torch.zeros(676, 25)\n",
    "train_losses_wol = []\n",
    "train_counter_wol = []\n",
    "test_losses_wol = []\n",
    "test_counter_wol = [i*len(train_loader_wol.dataset) for i in range(epochs + 1)]\n",
    "for epoch in range(1,epochs+1): \n",
    "    for i, data in enumerate(train_loader_wol): \n",
    "        # get the inputs \n",
    "        inputs, labels = data \n",
    "\n",
    "        # wrap them in Variable \n",
    "        inputs, labels = Variable(inputs), Variable(labels) \n",
    "        for j in range(676):\n",
    "            for k in range(25):\n",
    "                new_labels[labels[j], labels[k]] = 1\n",
    "        # Forward pass: Compute predicted y by passing x to the model \n",
    "        y_pred = model(inputs.float()) \n",
    "        # Compute and print loss \n",
    "        loss = criterion(y_pred, new_labels_wol.float()) \n",
    "        print(epoch, i, loss.data)\n",
    "        # Zero gradients, perform a backward pass, and update the weights. \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        train_losses_wol.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29172838f88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(train_losses_wol, label='training loss_wol')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
